{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Projects\\CartPole_NN_Policy\\mylib11\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [tf.keras.layers.Dense(5, activation=\"relu\"),\n",
    "tf.keras.layers.Dense(1, activation=\"sigmoid\")      #gives left probability neans 1 if 0 that means right\n",
    "]\n",
    "\n",
    "model = tf.keras.Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg= np.array([1,2,3])\n",
    "eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg[np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exploration an option before leaving the current action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg_policy(observation, model):\n",
    "    left_prob = model.predict(observation[np.newaxis])      #gives probability value between 0 and 1\n",
    "    action =  int(np.random.rand()>left_prob)               #value{0,1} gives exploration vs exploitation\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradients\n",
    "Optimize learnable parameters of policy by following the gradients towards higher reward (maximizing reward)\n",
    "\n",
    "## steps\n",
    "let the NN play the game multiple times and at every step just calculate the gradients (wrt reward) but dont apply it immidiately.\n",
    "Once you have completed several episodes then compute the actions using discounted method.\n",
    "result of previous step 2 can +ve or -ve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_step(env, observation, model, loss_fn):\n",
    "    with tf.GradientTape() as tape:\n",
    "        left_prabability = model(observation[np.newaxis])\n",
    "        action = (tf.random.uniform([1,1]) > left_prabability) # True and False\n",
    "        y_target = tf.constant([[1.]]) - tf.cast(action, tf.float32) # \n",
    "        loss = tf.reduce_mean(loss_fn(y_target, left_prabability)) \n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables) # dc/dw\n",
    "    new_observation, reward, done, info = env.step(int(action))\n",
    "    return new_observation, reward, done, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_multiple_episodes(env, n_episodes, n_max_steps, model, loss_fn):\n",
    "    all_rewards = list()\n",
    "    all_grads = list()\n",
    "    for episode in range(n_episodes):\n",
    "        current_rewards = list()\n",
    "        current_grads = list()\n",
    "        observation = env.reset()\n",
    "        for step in range(n_max_steps):\n",
    "            observation, reward, done, grads = play_one_step(env, observation, model, loss_fn)\n",
    "            current_rewards.append(reward)\n",
    "            current_grads.append(grads)\n",
    "            if done:\n",
    "                break\n",
    "        all_rewards.append(current_rewards)\n",
    "        all_grads.append(current_grads)\n",
    "    return all_rewards, all_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, discount_factor):\n",
    "    discounted = np.array(rewards)\n",
    "    N = len(rewards)\n",
    "    for step in range(N - 2, -1, -1):\n",
    "        # a_n + a_n+1*gamma\n",
    "        discounted[step] = discounted[step] + discounted[step + 1] * discount_factor\n",
    "    return discounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-22, -40, -50])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [10, 0, -50]\n",
    "discount_rewards(arr, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2])\n",
    "np.concatenate([x,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_and_normalize_rewards(all_rewards, discount_factor):\n",
    "    all_discounted_rewards = list()\n",
    "    for reward in all_rewards:\n",
    "        # discounted rewards\n",
    "        drs = discount_rewards(reward, discount_factor)\n",
    "        all_discounted_rewards.append(drs)\n",
    "\n",
    "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "    reward_mean = flat_rewards.mean()\n",
    "    reward_std = flat_rewards.std()\n",
    "\n",
    "    normalize_rewards = list()\n",
    "    for discounted_rewards in all_discounted_rewards:\n",
    "        nrs = (discounted_rewards - reward_mean) / reward_std\n",
    "        normalize_rewards.append(nrs)\n",
    "    return normalize_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 150\n",
    "n_episodes_per_update = 10\n",
    "n_max_steps = 200\n",
    "discount_factor = 0.95\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset(seed=SEED)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss_fn = tf.keras.losses.binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = [1,2,3]\n",
    "r2 = [-1,-2,3]\n",
    "all_rewards_1 = [r1, r2]\n",
    "list(map(sum, all_rewards_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(sum, all_rewards_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 3, 4])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [[1,2,3], [3,4,5]]\n",
    "tf.reduce_mean(arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1/150 mean rewards: 21.6\n",
      "Iteration: 2/150 mean rewards: 17.7\n",
      "Iteration: 3/150 mean rewards: 33.3\n",
      "Iteration: 4/150 mean rewards: 29.3\n",
      "Iteration: 5/150 mean rewards: 32.5\n",
      "Iteration: 6/150 mean rewards: 33.5\n",
      "Iteration: 7/150 mean rewards: 32.2\n",
      "Iteration: 8/150 mean rewards: 24.7\n",
      "Iteration: 9/150 mean rewards: 25.6\n",
      "Iteration: 10/150 mean rewards: 32.5\n",
      "Iteration: 11/150 mean rewards: 36.1\n",
      "Iteration: 12/150 mean rewards: 32.5\n",
      "Iteration: 13/150 mean rewards: 30.3\n",
      "Iteration: 14/150 mean rewards: 31.7\n",
      "Iteration: 15/150 mean rewards: 45.9\n",
      "Iteration: 16/150 mean rewards: 36.9\n",
      "Iteration: 17/150 mean rewards: 43.2\n",
      "Iteration: 18/150 mean rewards: 34.5\n",
      "Iteration: 19/150 mean rewards: 38.1\n",
      "Iteration: 20/150 mean rewards: 29.3\n",
      "Iteration: 21/150 mean rewards: 45.1\n",
      "Iteration: 22/150 mean rewards: 34.2\n",
      "Iteration: 23/150 mean rewards: 29.6\n",
      "Iteration: 24/150 mean rewards: 32.5\n",
      "Iteration: 25/150 mean rewards: 45.3\n",
      "Iteration: 26/150 mean rewards: 43.5\n",
      "Iteration: 27/150 mean rewards: 47.7\n",
      "Iteration: 28/150 mean rewards: 51.6\n",
      "Iteration: 29/150 mean rewards: 64.6\n",
      "Iteration: 30/150 mean rewards: 43.1\n",
      "Iteration: 31/150 mean rewards: 51.7\n",
      "Iteration: 32/150 mean rewards: 44.0\n",
      "Iteration: 33/150 mean rewards: 47.8\n",
      "Iteration: 34/150 mean rewards: 45.4\n",
      "Iteration: 35/150 mean rewards: 50.0\n",
      "Iteration: 36/150 mean rewards: 41.7\n",
      "Iteration: 37/150 mean rewards: 48.3\n",
      "Iteration: 38/150 mean rewards: 61.2\n",
      "Iteration: 39/150 mean rewards: 57.1\n",
      "Iteration: 40/150 mean rewards: 57.3\n",
      "Iteration: 41/150 mean rewards: 76.7\n",
      "Iteration: 42/150 mean rewards: 59.4\n",
      "Iteration: 43/150 mean rewards: 53.7\n",
      "Iteration: 44/150 mean rewards: 58.9\n",
      "Iteration: 45/150 mean rewards: 51.6\n",
      "Iteration: 46/150 mean rewards: 60.9\n",
      "Iteration: 47/150 mean rewards: 60.6\n",
      "Iteration: 48/150 mean rewards: 55.6\n",
      "Iteration: 49/150 mean rewards: 70.0\n",
      "Iteration: 50/150 mean rewards: 61.9\n",
      "Iteration: 51/150 mean rewards: 60.1\n",
      "Iteration: 52/150 mean rewards: 76.9\n",
      "Iteration: 53/150 mean rewards: 57.4\n",
      "Iteration: 54/150 mean rewards: 58.3\n",
      "Iteration: 55/150 mean rewards: 77.1\n",
      "Iteration: 56/150 mean rewards: 77.7\n",
      "Iteration: 57/150 mean rewards: 69.2\n",
      "Iteration: 58/150 mean rewards: 60.7\n",
      "Iteration: 59/150 mean rewards: 82.0\n",
      "Iteration: 60/150 mean rewards: 80.3\n",
      "Iteration: 61/150 mean rewards: 59.5\n",
      "Iteration: 62/150 mean rewards: 83.4\n",
      "Iteration: 63/150 mean rewards: 79.4\n",
      "Iteration: 64/150 mean rewards: 91.6\n",
      "Iteration: 65/150 mean rewards: 97.1\n",
      "Iteration: 66/150 mean rewards: 78.9\n",
      "Iteration: 67/150 mean rewards: 87.1\n",
      "Iteration: 68/150 mean rewards: 70.8\n",
      "Iteration: 69/150 mean rewards: 118.9\n",
      "Iteration: 70/150 mean rewards: 74.6\n",
      "Iteration: 71/150 mean rewards: 103.5\n",
      "Iteration: 72/150 mean rewards: 102.5\n",
      "Iteration: 73/150 mean rewards: 104.9\n",
      "Iteration: 74/150 mean rewards: 102.6\n",
      "Iteration: 75/150 mean rewards: 95.1\n",
      "Iteration: 76/150 mean rewards: 93.2\n",
      "Iteration: 77/150 mean rewards: 151.7\n",
      "Iteration: 78/150 mean rewards: 112.8\n",
      "Iteration: 79/150 mean rewards: 93.2\n",
      "Iteration: 80/150 mean rewards: 118.6\n",
      "Iteration: 81/150 mean rewards: 109.9\n",
      "Iteration: 82/150 mean rewards: 105.8\n",
      "Iteration: 83/150 mean rewards: 129.3\n",
      "Iteration: 84/150 mean rewards: 86.6\n",
      "Iteration: 85/150 mean rewards: 143.6\n",
      "Iteration: 86/150 mean rewards: 139.2\n",
      "Iteration: 87/150 mean rewards: 115.3\n",
      "Iteration: 88/150 mean rewards: 115.3\n",
      "Iteration: 89/150 mean rewards: 139.7\n",
      "Iteration: 90/150 mean rewards: 87.0\n",
      "Iteration: 91/150 mean rewards: 147.8\n",
      "Iteration: 92/150 mean rewards: 146.5\n",
      "Iteration: 93/150 mean rewards: 149.1\n",
      "Iteration: 94/150 mean rewards: 128.2\n",
      "Iteration: 95/150 mean rewards: 160.1\n",
      "Iteration: 96/150 mean rewards: 119.1\n",
      "Iteration: 97/150 mean rewards: 168.3\n",
      "Iteration: 98/150 mean rewards: 144.9\n",
      "Iteration: 99/150 mean rewards: 139.8\n",
      "Iteration: 100/150 mean rewards: 158.9\n",
      "Iteration: 101/150 mean rewards: 164.5\n",
      "Iteration: 102/150 mean rewards: 168.1\n",
      "Iteration: 103/150 mean rewards: 157.7\n",
      "Iteration: 104/150 mean rewards: 167.1\n",
      "Iteration: 105/150 mean rewards: 164.6\n",
      "Iteration: 106/150 mean rewards: 135.7\n",
      "Iteration: 107/150 mean rewards: 167.2\n",
      "Iteration: 108/150 mean rewards: 167.2\n",
      "Iteration: 109/150 mean rewards: 180.5\n",
      "Iteration: 110/150 mean rewards: 190.0\n",
      "Iteration: 111/150 mean rewards: 160.7\n",
      "Iteration: 112/150 mean rewards: 188.0\n",
      "Iteration: 113/150 mean rewards: 185.2\n",
      "Iteration: 114/150 mean rewards: 171.1\n",
      "Iteration: 115/150 mean rewards: 187.8\n",
      "Iteration: 116/150 mean rewards: 186.4\n",
      "Iteration: 117/150 mean rewards: 176.9\n",
      "Iteration: 118/150 mean rewards: 195.5\n",
      "Iteration: 119/150 mean rewards: 187.6\n",
      "Iteration: 120/150 mean rewards: 199.2\n",
      "Iteration: 121/150 mean rewards: 191.1\n",
      "Iteration: 122/150 mean rewards: 200.0\n",
      "Iteration: 123/150 mean rewards: 173.9\n",
      "Iteration: 124/150 mean rewards: 200.0\n",
      "Iteration: 125/150 mean rewards: 200.0\n",
      "Iteration: 126/150 mean rewards: 186.0\n",
      "Iteration: 127/150 mean rewards: 198.0\n",
      "Iteration: 128/150 mean rewards: 200.0\n",
      "Iteration: 129/150 mean rewards: 200.0\n",
      "Iteration: 130/150 mean rewards: 200.0\n",
      "Iteration: 131/150 mean rewards: 172.0\n",
      "Iteration: 132/150 mean rewards: 193.1\n",
      "Iteration: 133/150 mean rewards: 188.3\n",
      "Iteration: 134/150 mean rewards: 187.7\n",
      "Iteration: 135/150 mean rewards: 183.4\n",
      "Iteration: 136/150 mean rewards: 196.3\n",
      "Iteration: 137/150 mean rewards: 176.8\n",
      "Iteration: 138/150 mean rewards: 191.3\n",
      "Iteration: 139/150 mean rewards: 187.0\n",
      "Iteration: 140/150 mean rewards: 194.2\n",
      "Iteration: 141/150 mean rewards: 186.1\n",
      "Iteration: 142/150 mean rewards: 199.7\n",
      "Iteration: 143/150 mean rewards: 187.8\n",
      "Iteration: 144/150 mean rewards: 194.5\n",
      "Iteration: 145/150 mean rewards: 182.1\n",
      "Iteration: 146/150 mean rewards: 192.3\n",
      "Iteration: 147/150 mean rewards: 187.0\n",
      "Iteration: 148/150 mean rewards: 180.6\n",
      "Iteration: 149/150 mean rewards: 181.9\n",
      "Iteration: 150/150 mean rewards: 183.6\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(n_iterations):\n",
    "    all_rewards, all_grads = play_multiple_episodes(\n",
    "        env, n_episodes_per_update, n_max_steps, model, loss_fn\n",
    "    )\n",
    "    total_rewards = sum(map(sum, all_rewards))\n",
    "    print(f\"Iteration: {iteration + 1}/{n_iterations}\",\n",
    "    f\"mean rewards: {total_rewards/n_episodes_per_update}\"\n",
    "    )\n",
    "    all_final_rewards = discount_and_normalize_rewards(all_rewards, discount_factor)\n",
    "\n",
    "    all_mean_grads = list()\n",
    "    # Weight of 5 hidden nodes, bias for 5 nodes, w for output node, bias for output node\n",
    "    N = len(model.trainable_variables)\n",
    "    for var_index in range(N):\n",
    "        temp_reduce_mean = list()\n",
    "        for episode_index, final_rewards in enumerate(all_final_rewards): # rewards for every episode\n",
    "            for step, final_reward in enumerate(final_rewards): # several steps\n",
    "                result = final_reward * all_grads[episode_index][step][var_index]\n",
    "                temp_reduce_mean.append(result)\n",
    "        mean_grads = tf.reduce_mean(temp_reduce_mean, axis=0)\n",
    "        all_mean_grads.append(mean_grads)\n",
    "    optimizer.apply_gradients(zip(all_mean_grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "model is saved as 'model_at_Tue_Jul_12_17_35_24_2022_.h5'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "unique_name = re.sub(r\"[\\s+:]\", \"_\", time.asctime())\n",
    "model_name = f\"model_at_{unique_name}_.h5\"\n",
    "model.save(model_name)\n",
    "print(f\"model is saved as '{model_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, -1), (2, -2), (3, 3)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = [1,2,3]\n",
    "r2 = [-1,-2,3]\n",
    "list(zip(r1, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Projects\\CartPole_NN_Policy\\mylib11\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(211, array([2.175206  , 0.7111561 , 0.21600634, 0.9366191 ], dtype=float32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_one_episode(policy, model, n_max_steps=500, seed=42):\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    obs = env.reset()\n",
    "    for step in range(n_max_steps):\n",
    "        env.render()\n",
    "        action = policy(obs, model)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "    env.close()\n",
    "    return step, obs\n",
    "\n",
    "show_one_episode(pg_policy, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_policy(obs, model):\n",
    "    PoleAngle = obs[2] \n",
    "    if PoleAngle < 0: # falling left\n",
    "        return 0 # Move left\n",
    "    return 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34,\n",
       " array([ 0.20117114,  0.54828346, -0.2290762 , -0.78777736], dtype=float32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "show_one_episode(basic_policy, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(149,\n",
       " array([-2.4206684 , -2.1997023 ,  0.01727703,  0.36243927], dtype=float32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_one_episode(pg_policy, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c631db70dfbf3ffe5f100979aa481a7ec6d87507ac0ea6bdf833b60e623c4416"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
